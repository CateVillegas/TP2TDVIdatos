{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Importar las librerías necesarias\n",
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from pandas.api.types import is_numeric_dtype\n",
    "import gc\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.tree import DecisionTreeClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.metrics import roc_auc_score\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Cargar los datos\n",
    "files = [\"datosTP2/ctr_15.csv\", \"datosTP2/ctr_16.csv\", \"datosTP2/ctr_17.csv\", \"datosTP2/ctr_18.csv\", \"datosTP2/ctr_19.csv\", \"datosTP2/ctr_20.csv\", \"datosTP2/ctr_21.csv\"]\n",
    "combined_data = pd.concat([pd.read_csv(f) for f in files])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the test data\n",
    "eval_data = pd.read_csv(\"datosTP2/ctr_test.csv\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Feature Engineering: Add 'ad_size' (creative_height * creative_width)\n",
    "combined_data['ad_size'] = combined_data['creative_height'] * combined_data['creative_width']\n",
    "eval_data['ad_size'] = eval_data['creative_height'] * eval_data['creative_width']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "7"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# Split the combined data into train and validation sets with a fixed random state\n",
    "random_seed = 2345\n",
    "combined_data = combined_data.sample(frac=8/10, random_state=random_seed)\n",
    "y = combined_data[\"Label\"]\n",
    "X = combined_data.drop(columns=[\"Label\"])\n",
    "\n",
    "# Split into training and validation sets\n",
    "X_train, X_val, y_train, y_val = train_test_split(X, y, test_size=0.2, random_state=random_seed)\n",
    "\n",
    "del combined_data, X, y\n",
    "gc.collect()\n",
    "# Ahora X_train y X_val contienen tanto variables numéricas como categóricas."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Suponiendo que ya tienes X_train, y_train, X_val y eval_data\n",
    "\n",
    "# Identificar las variables categóricas en el conjunto de entrenamiento\n",
    "categorical_features = X_train.select_dtypes(include=['object', 'category']).columns.tolist()\n",
    "\n",
    "# Codificación por conteo\n",
    "for feature in categorical_features:\n",
    "    counts = X_train[feature].value_counts()\n",
    "    X_train[feature + '_count'] = X_train[feature].map(counts)\n",
    "    X_val[feature + '_count'] = X_val[feature].map(counts)\n",
    "\n",
    "# Eliminar las variables categóricas originales si es necesario\n",
    "X_train_final = X_train.drop(columns=categorical_features).reset_index(drop=True)\n",
    "X_val_final = X_val.drop(columns=categorical_features).reset_index(drop=True)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.decomposition import PCA\n",
    "from sklearn.ensemble import RandomForestClassifier\n",
    "from sklearn.pipeline import make_pipeline\n",
    "from sklearn.impute import SimpleImputer\n",
    "from sklearn.model_selection import RandomizedSearchCV\n",
    "\n",
    "# Definir el pipeline con PCA y Random Forest\n",
    "pipeline = make_pipeline(\n",
    "    SimpleImputer(),       # Para manejar valores faltantes\n",
    "    PCA(n_components=10),  # Seleccionamos 10 componentes principales (ajusta este valor según sea necesario)\n",
    "    RandomForestClassifier(random_state=42, n_jobs=-1)  # Modelo Random Forest\n",
    ")\n",
    "\n",
    "# Hiperparámetros para RandomizedSearchCV\n",
    "param_distributions = {\n",
    "    'randomforestclassifier__n_estimators': [50, 100],  # Número de árboles\n",
    "    'randomforestclassifier__max_depth': [4, 6, 8],  # Profundidad del árbol\n",
    "    'randomforestclassifier__min_samples_split': [2, 5],\n",
    "    'randomforestclassifier__min_samples_leaf': [1, 2],\n",
    "}\n",
    "\n",
    "# RandomizedSearchCV para encontrar los mejores hiperparámetros\n",
    "random_search = RandomizedSearchCV(pipeline, param_distributions, n_iter=10, cv=3, verbose=1, n_jobs=-1, scoring='roc_auc', random_state=42)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Fitting 3 folds for each of 10 candidates, totalling 30 fits\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "c:\\Users\\catev\\anaconda3\\envs\\TD6\\Lib\\site-packages\\joblib\\externals\\loky\\process_executor.py:752: UserWarning: A worker stopped while some jobs were given to the executor. This can be caused by a too short worker timeout or by a memory leak.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "# Entrenar el modelo con los datos de entrenamiento\n",
    "random_search.fit(X_train, y_train)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Evaluar el modelo en el conjunto de validación\n",
    "y_val_preds = random_search.predict_proba(X_val)[:, 1]\n",
    "val_auc_roc = roc_auc_score(y_val, y_val_preds)\n",
    "print(f'Validation AUC-ROC: {val_auc_roc:.4f}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Predecir en el conjunto de evaluación\n",
    "eval_data_pca = eval_data.select_dtypes(include='number')\n",
    "y_preds = random_search.predict_proba(eval_data_pca.drop(columns=[\"id\"]))[:, 1]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Hacer el archivo de submission\n",
    "submission_df = pd.DataFrame({\"id\": eval_data[\"id\"], \"Label\": y_preds})\n",
    "submission_df[\"id\"] = submission_df[\"id\"].astype(int)\n",
    "submission_df.to_csv(\"random_forest_pca_submission.csv\", sep=\",\", index=False)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "TD6",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.12.4"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
